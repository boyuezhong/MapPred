"""
This is a standalone version of Mappred Server for predicting contact map or distance between residues without any homologous templates.

Input : 
1. 231 covar matrices (i.e. xxx.231stats) and  frobenius matrix (i.e. xxx.frobstats) generated by cov231stats, or 441 covar matrices generated by cov21stats.
2. contact map (xxx.ccmpred) predicted by Ccmpred.
3. second structure (xxx.ss2) predicted by PSIPRED
4. solvent accessibility (xxx.solv) predicted by SOLVPRED

Output:
a contact matrix of  [L,L]
a distance distribution matrix of [L,L,26]
[0,4.0,4.5,5.0,5.5,6.0,6.5,7.0,7.5,8.0,8.5,9.0,9.5,10.0,10.5,11.0,11.5,12.0,12.5,13.0,13.5,14.0,14.5,15.0,15.5,16.0,inf]
a distance matrix of [L,L]

output format: [text|numpy]

*NOTE*: 
Author: Qi Wu, Nankai University, E-mail: wuqird@aliyun.com, Github: https://github.com/AtlasWuqi/mappred
version: 1.0
date: Apr 8, 2019
"""

import numpy as np
from keras.models import load_model
import math, time, os, sys, gc, getopt
import tensorflow as tf
from keras.backend.tensorflow_backend import set_session

#---------collect data ------------------------------------------
def get_channel_1DTO2D(feature, lens):
	cs = feature.shape[1]
	matrix = np.zeros( (lens, lens, cs*2), dtype=np.float32)
	for c in range(cs):
		matrix[:, :, c]    =  np.tile(feature[:, c].reshape(lens,1),(1,lens))
		matrix[:, :, c+cs] =  np.tile(feature[:, c].reshape(1,lens),(lens,1))
	return matrix

def get_feature_per_residue(filename, lens, offset=3):
	lines = getlines(filename)
	a = []
	for line in lines:
		if line.startswith('#') or len(line)<10:
			continue
		a.append( line.split()[offset:] )
	if len(a) != lens:
		print ( "the length of sequence in %s is not equal %d" % (filename, lens) )
		sys.exit(1)
	return np.asarray(a,dtype=np.float32)

def get_channel_ss(name, lens):
	ss = get_feature_per_residue(name + ".ss2", lens)
	solv = get_feature_per_residue(name + ".solv", lens, 2)
	feature = np.concatenate( (ss, solv ), axis=1)
	return get_channel_1DTO2D(feature, lens)

def get_ccmpred(filename, lens):
	lines = getlines(filename)
	if len(lines) < lens :
		print ("[warning] %s is invalid, " % filename )
		return np.zeros( (lens,lens, 1), dtype=np.float32)
	else:
		x = np.loadtxt(filename, dtype=np.float32)
		y =  ( x + np.transpose(x) ) /2
		return y.reshape(lens,lens,1)

def get_231_data(name, lens):
	inputfile = name + '-v231-p0.npy'
	if  os.path.exists(inputfile) :
		return  np.load(inputfile)
	inputfile = name + '.231stats'
	if  os.path.exists(inputfile) :
		return np.fromfile(inputfile, dtype=np.float32).reshape(1,231,lens,lens)
	inputfile = name + '.21stats'
	if  os.path.exists(inputfile) :
		return reduce_dim(inputfile,lens)
	inputfile = name + '.aln.21stats'
	if  os.path.exists(inputfile) :
		return reduce_dim(inputfile,lens)
	print ("[error]not found 231stats or 21stats in path %s, check it, please " % name)
	sys.exit(1)

def get_frobenius(name,lens):
	inputfile = name + '-vfrob.npy'
	if  os.path.exists(inputfile) :
		return  np.load(inputfile)
	inputfile = name + '.frobstats'
	if  os.path.exists(inputfile) :
		return np.fromfile(inputfile, dtype=np.float32).reshape(lens,lens)
	inputfile = name + '.21stats'
	if  os.path.exists(inputfile) :
		data = np.fromfile(inputfile, dtype=np.float32).reshape(441,lens,lens)
		return np.sqrt(np.sum(np.square(data), axis=0))
	inputfile = name + '.aln.21stats'
	if  os.path.exists(inputfile) :
		data = np.fromfile(inputfile, dtype=np.float32).reshape(441,lens,lens)
		return np.sqrt(np.sum(np.square(data), axis=0))
	print ("[error]not found frobstats or 21stats in path %s, check it, please " % name)
	sys.exit(1)

def get_features(name, size, x):
	lens = get_seq_lens(name)
	#deepmsa  = np.load(name + 'deepmsa.npy').reshape(lens,lens, 1)
	deepmsa = x.reshape(lens,lens, 1)
	ss = get_channel_ss(name, lens)
	ccmpred = get_ccmpred(name+'.ccmpred', lens)
	frobenius = get_frobenius(name, lens).reshape(lens,lens,1)
	features = np.concatenate((frobenius, deepmsa, ccmpred, ss), axis=2)
	return split_matrix(features, int(size))

#------data preprocessing----------------------------
def getlines(filename):
	fo = open(filename, "r",10240)
	try:
		try:
			return fo.readlines()
		finally:
			fo.close()
	except Exception:
		sys.exit(1)

def getfirstline(filename):
	fo = open(filename, "r",10240)
	try:
		try:
			return fo.readline()
		finally:
			fo.close()
	except Exception:
		sys.exit(1)

def get_seq_lens(name):
	return len(getfirstline(name + ".aln")) - 1

def split_matrix(matrix,size=224):
	seqlen = matrix.shape[0]
	num = seqlen/size
	if seqlen%size != 0:
		num+=1
	subs = np.zeros( (num*num, size,size, matrix.shape[2]), dtype=np.float32)
	index = 0
	if num == 1:
		subs[index,0:seqlen, 0:seqlen] = matrix
		return subs
	for i in range(num):
		for j in range(num):
			if size*(i+1) <= seqlen :
				if size*(j+1) <= seqlen :	
					subs[index] = matrix[size*i:size*(i+1), size*j:size*(j+1)]
				else:
					subs[index] = matrix[size*i:size*(i+1), (seqlen-size):seqlen]
			else:
				if size*(j+1) <= seqlen :
					subs[index] = matrix[(seqlen-size):seqlen, size*j:size*(j+1)]
				else:
					subs[index] = matrix[(seqlen-size):seqlen, (seqlen-size):seqlen]
			index+=1
	return subs

def merge_label(subs, seqlen,size=224):
	num = seqlen/size
	if seqlen%size != 0:
		num+=1
	index = 0
	channel = subs[index].shape[-1]
	
	if num == 1:
		return subs[index][0:seqlen, 0:seqlen]
	matrix = np.zeros( (seqlen,seqlen, channel), dtype=np.float32)
	counts = np.zeros( (seqlen,seqlen, channel), dtype=np.int32)
	for i in range(num):
		for j in range(num):
			sub = subs[index]
			if size*(i+1) <= seqlen :
				if size*(j+1) <= seqlen :
					matrix[size*i:size*(i+1), size*j:size*(j+1)] += sub
					counts[size*i:size*(i+1), size*j:size*(j+1)] += 1
				else:
					matrix[size*i:size*(i+1), (seqlen-size):seqlen] += sub
					counts[size*i:size*(i+1), (seqlen-size):seqlen] += 1
			else:
				if size*(j+1) <= seqlen :
					matrix[(seqlen-size):seqlen, size*j:size*(j+1)] += sub
					counts[(seqlen-size):seqlen, size*j:size*(j+1)] += 1
				else:
					matrix[(seqlen-size):seqlen, (seqlen-size):seqlen] += sub
					counts[(seqlen-size):seqlen, (seqlen-size):seqlen] += 1
			index+=1
	return matrix/counts

def reduce_dim(inputfile,lens):
	data = np.fromfile(inputfile, dtype=np.float32).reshape(441,lens,lens)
	rdata = np.zeros( (231,lens,lens), dtype=np.float32)
	cnt=0
	for i in range(21):
		for j in range(i):
			rdata[cnt]=data[i*21+j]+data[j*21+i]
			cnt+=1
		rdata[cnt]=data[i*21+i]
		cnt+=1
	return rdata.reshape(1,231,lens,lens)


#-----------predict deepmsa---------------
def predict_deepmsa(model_dir, data_dir, target):
	path = data_dir + os.sep + target
	ensemblefile = path + 'deepmsa.npy'
	if os.path.exists( ensemblefile ):
		print ("[info]%s existed, skip" % ensemblefile)
		return np.load( ensemblefile )

	lens = get_seq_lens(path)
	x_test =  get_231_data(path, lens)
	y_ensemble = None
	size=3
	for index in range(1, size+1):
		taskname='deepmsa'+str(index)
		modelfile = model_dir + taskname + '.h5'
		if not os.path.exists(modelfile):
			print ("[error]not found modelfile %s, check it, please" % modelfile)
			sys.exit(1)
		model =  load_model( modelfile )
		#channel_first bins(5,6,7,8,9,10)
		y_pred = model.predict(x_test, batch_size=1)
		if y_pred.shape[1]!= 1:
			y_merg = np.sum(y_pred[0][0:4], axis=0)
		else:
			y_merg = y_pred[0][0]
		if y_ensemble is None:
			y_ensemble = y_merg
		else:
			y_ensemble += y_merg
	x = y_ensemble/size
	x = ( x + x.transpose() ) /2
	#np.save(ensemblefile, x)
	return x

#-----------predict deepmeta---------------
def predict_deepmeta(model_dir, data_dir, target, size, batch_size, deepmsa, ensemblefile, output_npy=False):
	path = data_dir + os.sep + target
	#ensemblefile = path + '.mappredv2'
	if os.path.exists( ensemblefile ):
		print ("[info]%s existed, skip" % ensemblefile)
		return
	lens = get_seq_lens(path)
	x_test = get_features(path, size, deepmsa)
	y_ensemble = None
	size=4
	for index in range(1, size+1):
		taskname='deepmeta' + str(index)
		modelfile = model_dir + taskname + '.h5'
		if not os.path.exists(modelfile):
			print ("[error]not found modelfile %s, check it, please" % modelfile)
			sys.exit(1)
		model =  load_model( modelfile )
		#channel_last
		y_pred = model.predict(x_test, batch_size=batch_size)
		y_merg = merge_label(y_pred, lens, x_test.shape[1])
		if y_ensemble is None:
			y_ensemble = y_merg
		else:
			y_ensemble += y_merg
	x = y_ensemble/size

	chans = x.shape[-1]
	if chans == 1:
		x = x[:,:,0]
		y =  ( x + np.transpose(x) ) /2
	else:
		y =  ( x + np.transpose(x, [1,0,2]) ) /2
	if output_npy:
		np.save( ensemblefile, y)
	elif chans == 1:
		output_cont(ensemblefile, y)
	else:
		output_dist(ensemblefile, y)

#---------------output result-------------
def output_cont(outputfile, cmap, delimiter=' '):
	lens = len(cmap)
	fo = open(outputfile, "w",10240)
	for i in range(lens):
		for j in range(i+1, lens):
			dis    =  '{:.6f}'.format(  cmap[i][j]  )
			fo.write( str(i+1) + delimiter + str(j+1) + ' 0 8 ' + dis + os.linesep )
	fo.close()

def output_dist(outputfile, cmap, delimiter=' '):
	lens = len(cmap)
	fo = open(outputfile, "w",10240)
	for i in range(lens):
		for j in range(i+1, lens):
			distri = cmap[i][j]
			dis    = delimiter.join( '{:.4f}'.format(x) for x in distri)
			fo.write( str(i+1) + delimiter + str(j+1) + delimiter + dis + os.linesep )
	fo.close()

def usage():
	print ("usage: python mappred-predictor.py [options]  data_dir model_dir")
	print ("options:")
	print ("-u GPU card ID : select from 0-3 (default 0,1)")
	print ("-t target name without filename extension (default T0950)")
	print ("-h help : print some help information")

def main():
	try:
		opts, args = getopt.getopt(sys.argv[1:], "u:t:b:o:h")
	except getopt.GetoptError as err:
		print ( str(err) )
		usage()
		sys.exit(2)
	cuda = '0,1'
	data_dir   = '/dl/wuqi/data/wu/casp13e/T0950/'
	model_dir  = '/dl/wuqi/data/wu/select/'
	target = 'T0950'
	batch_size = 8
	size = '224'
	bins=26
	outputfile = '-1'
	for o, a in opts:
		if o == "-u":
			cuda = a
		elif o == "-t":
			target = a
		elif o == "-b":
			bins = int(a)
		elif o == "-o":
			outputfile = a
		elif o == "-h":
			usage()
			sys.exit(0)
		else:
			print ("[error]Not recognized option[%s %s]" % (o,a))
			sys.exit(1)
	os.environ["CUDA_VISIBLE_DEVICES"] = cuda
	config = tf.ConfigProto()
	config.gpu_options.per_process_gpu_memory_fraction = 0.95
	set_session(tf.Session(config=config))
	if len(args) ==1 :
		data_dir   = args[0] + os.sep
	elif len(args) == 2:
		data_dir   = args[0] + os.sep
		model_dir  = args[1] + os.sep
	else:
		print ("[warning] check paras")

	if outputfile == '-1':
		outputfile =  data_dir + os.sep + target + '.mappred'
	if os.path.exists( outputfile ):
		print ("[info]%s existed, skip" % outputfile)
		sys.exit(0)

	stime = time.time()
	print ("start at %s" % (time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()) ) )
	deepmsa = predict_deepmsa(model_dir, data_dir, target)
	predict_deepmeta(model_dir, data_dir, target, size, batch_size, deepmsa, outputfile)
	stime2 = time.time()
	costtime = stime2-stime
	print ( "end at %s, costtime=%f" % (time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()), costtime) )
	print ( "%s %f" % (target, costtime) )

if __name__ == "__main__":
	main()
